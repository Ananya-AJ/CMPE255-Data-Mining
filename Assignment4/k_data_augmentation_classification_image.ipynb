{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbfK9Y7aCpWqW1CwWIkuNw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-AJ/CMPE255-Data-Mining/blob/main/Assignment4/k_data_augmentation_classification_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "soC0Yo9ZUlXo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hSLHUCTd7DHD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "subset of the Dogs vs Cats dataset, which contains 8,000 images of dogs and cats (4,000 images of each). We'll split the dataset into training and testing sets."
      ],
      "metadata": {
        "id": "gx8EWBG7RGg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Download dataset\n",
        "url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "filename = 'cats_and_dogs_filtered.zip'\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Extract dataset\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ],
      "metadata": {
        "id": "i7cj-GVCQ_X5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Set up directories\n",
        "base_dir = 'cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Set up data generators with data augmentation\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "# Define and compile model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=50,\n",
        "    epochs=5,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=50)\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFtNEDHHSvm7",
        "outputId": "da15060e-0d15-4a30-acd9-716bb91062f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "<ipython-input-11-4b14e4c98a9f>:54: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.7688 - accuracy: 0.5070 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.6941 - accuracy: 0.4830 - val_loss: 0.6921 - val_accuracy: 0.5210\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 98s 2s/step - loss: 0.6933 - accuracy: 0.5160 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.6914 - accuracy: 0.5130 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 75s 2s/step - loss: 0.6917 - accuracy: 0.5240 - val_loss: 0.6829 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-4b14e4c98a9f>:62: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5\n"
          ]
        }
      ]
    }
  ]
}