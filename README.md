Assignment 1 :
Used Git-copilot to explore its auto code completion features by working on a cars.csv data set( used pandas to read, manipulate and played around on data using copilot).

Tried some sorting algorithms which auto completed like magic.

Please find the screen recording of the same below.

https://youtu.be/WDslXbnnX9U


Practiced Auto ML using Jadbio

Used a students score data set from Kaggle that has two columns, Number of hours, scores and predictions are made of scores based on number of hours using linear regression. Please find the link below for the same.

https://youtu.be/FemJhQiyDVw

Used lung cancer data set to analyse on different features and applied different models to look how results change with a minimal delta. Please refer to the screen recording of the same below:

https://youtu.be/2YxkLGHClB0

Assignment 2: 
Practice Derek Banas tutorial


Assignment 3: Pycaret and gradio

The folder contains colab notebooks of below data mining methods on different datasets

Binary classification - Heart strokedataset from kaggle - predicting stroke Multiclass classification - Star dataset from kaggle - predicting start type Regression - House price prediction from kaggle - predicting sale price Clustering - Bank marketing campaign from kaggle Anomaly Detection - Marketing campaign of a bank dataset from kaggle Association Rules Mining - market basket dataset from kaggle Time Series Forecasting - Univariate without Exogenous Variables - Air passenger dataset from kaggle, forecasting the frequency of passenger to fly Time Series Forecasting - Univariate with Exogenous Variables - htag property holdings,property sale data from kaggle

All the above methods were practiced using both pycaret and explicit cleaning using pandas.

Gradio is used on binary classification and regression


Assignment 4:

1) Complete EDA is in CompleteEDA_d3_seaborn_bokeh_visualizations folder
2) Auto EDA assignment is in Auto_EDA
3)Apache beam assignment is in Apache_Beam folder

Each of these folders have link to colab, datasets if have to be uploaded seperately or kaggle token if datasets are to be downloaded to colab.
Each of these folders have their own readme files that give an extra information on what colab contains and how to run.
